{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udeCAYUj0VSE",
        "outputId": "38deea90-5493-4843-80f9-4465a3d692bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descargando indicador: gdp_pc (NY.GDP.PCAP.CD)...\n",
            "Descargando indicador: life_exp (SP.DYN.LE00.IN)...\n",
            "Descargando indicador: urban_pct (SP.URB.TOTL.IN.ZS)...\n",
            "Descargando indicador: co2_pc (EN.GHG.CO2.PC.CE.AR5)...\n",
            "Descargando indicador: unemp (SL.UEM.TOTL.ZS)...\n",
            "Descargando indicador: infl (FP.CPI.TOTL.ZG)...\n",
            "Descargando indicador: trade_gdp (NE.TRD.GNFS.ZS)...\n",
            "Descargando indicador: internet (IT.NET.USER.ZS)...\n",
            "\n",
            "[OK] Dataset guardado en: outputs/data/wdi_dataset.csv\n",
            "\n",
            "Primeras filas:\n",
            "  iso3c                      country  year       gdp_pc   life_exp  urban_pct  \\\n",
            "0   AFE  Africa Eastern and Southern  2023  1571.449189  65.146154  37.772301   \n",
            "1   AFE  Africa Eastern and Southern  2022  1679.327622  64.487020  37.360578   \n",
            "2   AFE  Africa Eastern and Southern  2021  1562.416175  62.979999  36.908543   \n",
            "3   AFE  Africa Eastern and Southern  2020  1351.591669  63.766484  36.488322   \n",
            "4   AFE  Africa Eastern and Southern  2019  1507.085600  63.857261  36.097331   \n",
            "\n",
            "     co2_pc     unemp       infl  trade_gdp  internet  \n",
            "0  0.838104  7.676548   7.399186  56.170528      27.8  \n",
            "1  0.858132  7.869470  10.883478  57.152776      26.8  \n",
            "2  0.899170  8.407412   6.824727  54.501265      25.0  \n",
            "3  0.897581  7.974302   5.191629  49.521705      23.5  \n",
            "4  0.984697  7.459106   4.102851  53.528129      21.6  \n",
            "\n",
            "Nulos por columna (ordenado):\n",
            "trade_gdp    513\n",
            "internet     487\n",
            "unemp        383\n",
            "infl         371\n",
            "co2_pc       177\n",
            "iso3c          0\n",
            "country        0\n",
            "year           0\n",
            "urban_pct      0\n",
            "gdp_pc         0\n",
            "life_exp       0\n",
            "dtype: int64\n",
            "\n",
            "Dimensión final (filas, columnas): (3568, 11)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# PROYECTO ABP - Dataset público (World Bank WDI)\n",
        "# SECCIÓN 1: Descargar, unir, limpiar y guardar CSV\n",
        "# ==========================================\n",
        "\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "# ---------------------------\n",
        "# Configuración de salida\n",
        "# ---------------------------\n",
        "OUT_DIR = \"outputs\"\n",
        "DATA_DIR = os.path.join(OUT_DIR, \"data\")\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "# Base URL de la API del Banco Mundial (World Bank)\n",
        "BASE = \"https://api.worldbank.org/v2\"\n",
        "\n",
        "# ---------------------------\n",
        "# Indicadores WDI\n",
        "# Elegimos una variable objetivo (y) y varias explicativas (X)\n",
        "# y = PIB per cápita (US$ corrientes)\n",
        "# ---------------------------\n",
        "INDICATORS = {\n",
        "    \"gdp_pc\": \"NY.GDP.PCAP.CD\",        # PIB per cápita (US$ corrientes) -> variable objetivo\n",
        "    \"life_exp\": \"SP.DYN.LE00.IN\",      # Esperanza de vida al nacer (años)\n",
        "    \"urban_pct\": \"SP.URB.TOTL.IN.ZS\",  # Población urbana (% del total)\n",
        "    \"co2_pc\": \"EN.GHG.CO2.PC.CE.AR5\",        # Emisiones CO2 (toneladas métricas per cápita)\n",
        "    \"unemp\": \"SL.UEM.TOTL.ZS\",         # Desempleo (% fuerza laboral)\n",
        "    \"infl\": \"FP.CPI.TOTL.ZG\",          # Inflación (IPC, % anual)\n",
        "    \"trade_gdp\": \"NE.TRD.GNFS.ZS\",     # Comercio (% del PIB)\n",
        "    \"internet\": \"IT.NET.USER.ZS\",      # Usuarios de internet (% de la población)\n",
        "}\n",
        "\n",
        "# Rango de años para construir un panel país-año\n",
        "START_YEAR = 2010\n",
        "END_YEAR = 2023\n",
        "\n",
        "def wb_fetch_indicator(ind_code: str, start_year: int, end_year: int, per_page: int = 20000) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Descarga un indicador para \"todos los países\" (country/all) en un rango de años.\n",
        "    Devuelve un DataFrame con columnas:\n",
        "      - iso3c: código ISO3 del país\n",
        "      - country: nombre del país\n",
        "      - year: año (int)\n",
        "      - value: valor numérico del indicador (float)\n",
        "    \"\"\"\n",
        "    url = f\"{BASE}/country/all/indicator/{ind_code}\"\n",
        "    params = {\n",
        "        \"format\": \"json\",\n",
        "        \"per_page\": per_page,\n",
        "        \"date\": f\"{start_year}:{end_year}\",\n",
        "        \"page\": 1\n",
        "    }\n",
        "\n",
        "    # Primera llamada para conocer cuántas páginas hay\n",
        "    r = requests.get(url, params=params, timeout=60)\n",
        "    r.raise_for_status()\n",
        "    payload = r.json()\n",
        "\n",
        "    # payload[0] = metadata, payload[1] = datos\n",
        "    if len(payload) < 2 or (isinstance(payload[1], list) and not payload[1]): # Check if data part exists and is not empty\n",
        "        print(f\"Warning: No data found for indicator {ind_code} between {start_year}-{end_year}. Returning empty DataFrame.\")\n",
        "        # Return an empty DataFrame with expected columns if no data is found\n",
        "        return pd.DataFrame(columns=[\"iso3c\", \"country\", \"year\", \"value\"])\n",
        "\n",
        "    meta = payload[0]\n",
        "    data = payload[1]\n",
        "\n",
        "    pages = int(meta.get(\"pages\", 1))\n",
        "\n",
        "    # Parseamos la primera página\n",
        "    rows = []\n",
        "    for item in data:\n",
        "        if item is None:\n",
        "            continue\n",
        "        country = item.get(\"country\", {}).get(\"value\")\n",
        "        iso3c = item.get(\"countryiso3code\")\n",
        "        year = item.get(\"date\")\n",
        "        val = item.get(\"value\")\n",
        "        rows.append((iso3c, country, int(year), val))\n",
        "\n",
        "    # Si hay más páginas, las recorremos y acumulamos\n",
        "    for p in range(2, pages + 1):\n",
        "        params[\"page\"] = p\n",
        "        r = requests.get(url, params=params, timeout=60)\n",
        "        r.raise_for_status()\n",
        "        payload = r.json()\n",
        "        # Again, check if data part exists for subsequent pages\n",
        "        if len(payload) < 2 or (isinstance(payload[1], list) and not payload[1]):\n",
        "            print(f\"Warning: No data found for indicator {ind_code} on page {p}. Stopping further fetching for this indicator.\")\n",
        "            break # Stop fetching if no data on subsequent pages\n",
        "        data = payload[1]\n",
        "\n",
        "        for item in data:\n",
        "            if item is None:\n",
        "                continue\n",
        "            country = item.get(\"country\", {}).get(\"value\")\n",
        "            iso3c = item.get(\"countryiso3code\")\n",
        "            year = item.get(\"date\")\n",
        "            val = item.get(\"value\")\n",
        "            rows.append((iso3c, country, int(year), val))\n",
        "\n",
        "        # Pausa pequeña para ser amable con la API\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    # Construimos DataFrame\n",
        "    df = pd.DataFrame(rows, columns=[\"iso3c\", \"country\", \"year\", \"value\"])\n",
        "\n",
        "    # Convertimos a numérico (lo que no se pueda, queda como NaN)\n",
        "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "# ---------------------------\n",
        "# 1) Descargar cada indicador y renombrar \"value\" con el nombre corto del indicador\n",
        "# ---------------------------\n",
        "dfs = []\n",
        "for name, code in INDICATORS.items():\n",
        "    print(f\"Descargando indicador: {name} ({code})...\")\n",
        "    dfi = wb_fetch_indicator(code, START_YEAR, END_YEAR)\n",
        "    # Only append if the DataFrame is not empty\n",
        "    if not dfi.empty:\n",
        "        dfi = dfi.rename(columns={\"value\": name})\n",
        "        dfs.append(dfi)\n",
        "    else:\n",
        "        print(f\"Skipping {name} due to no data.\")\n",
        "\n",
        "# Check if any data was successfully downloaded\n",
        "if not dfs:\n",
        "    print(\"Error: No data frames were successfully downloaded. Cannot proceed with merging.\")\n",
        "else:\n",
        "    # ---------------------------\n",
        "    # 2) Unir (merge) por país-año para armar el panel final\n",
        "    #    Partimos con el primero y luego vamos uniendo los demás\n",
        "    # ---------------------------\n",
        "    df = dfs[0]\n",
        "    for dfi in dfs[1:]:\n",
        "        # Unimos solo la columna del indicador nuevo para evitar duplicar country/iso3c innecesariamente\n",
        "        indicador_col = dfi.columns[-1]\n",
        "        df = df.merge(dfi[[\"iso3c\", \"year\", indicador_col]], on=[\"iso3c\", \"year\"], how=\"left\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # 3) Limpieza mínima:\n",
        "    #    - eliminar filas sin iso3c\n",
        "    #    - filtrar códigos ISO3 válidos (largo 3)\n",
        "    # ---------------------------\n",
        "    df = df.dropna(subset=[\"iso3c\"])\n",
        "    df = df[df[\"iso3c\"].astype(str).str.len() == 3].copy()\n",
        "\n",
        "# ---------------------------\n",
        "# 4) Para poder hacer regresión, necesitamos observar la variable objetivo (gdp_pc)\n",
        "#    Por eso eliminamos filas donde gdp_pc es NaN\n",
        "# ---------------------------\n",
        "\n",
        "# WARNING: si por algún motivo no está la columna objetivo, detenemos el script\n",
        "if \"gdp_pc\" not in df.columns:\n",
        "    warnings.warn(\n",
        "        \"No se descargó la columna 'gdp_pc'. No se puede continuar. \"\n",
        "        f\"Columnas disponibles: {list(df.columns)}\",\n",
        "        category=UserWarning\n",
        "    )\n",
        "    raise SystemExit(1)\n",
        "\n",
        "df = df.dropna(subset=[\"gdp_pc\"]).copy()\n",
        "\n",
        "# ---------------------------\n",
        "# 5) Guardar dataset final como CSV (reproducible)\n",
        "# ---------------------------\n",
        "out_path = os.path.join(DATA_DIR, \"wdi_dataset.csv\")\n",
        "df.to_csv(out_path, index=False)\n",
        "\n",
        "print(f\"\\n[OK] Dataset guardado en: {out_path}\")\n",
        "print(\"\\nPrimeras filas:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nNulos por columna (ordenado):\")\n",
        "print(df.isna().sum().sort_values(ascending=False))\n",
        "\n",
        "print(\"\\nDimensión final (filas, columnas):\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb023a75",
        "outputId": "e8854559-e58c-44d5-f232-31cbf07df9b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- INFO GENERAL ---\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3568 entries, 0 to 3567\n",
            "Data columns (total 11 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   iso3c      3568 non-null   object \n",
            " 1   country    3568 non-null   object \n",
            " 2   year       3568 non-null   int64  \n",
            " 3   gdp_pc     3568 non-null   float64\n",
            " 4   life_exp   3568 non-null   float64\n",
            " 5   urban_pct  3568 non-null   float64\n",
            " 6   co2_pc     3391 non-null   float64\n",
            " 7   unemp      3185 non-null   float64\n",
            " 8   infl       3197 non-null   float64\n",
            " 9   trade_gdp  3055 non-null   float64\n",
            " 10  internet   3081 non-null   float64\n",
            "dtypes: float64(8), int64(1), object(2)\n",
            "memory usage: 306.8+ KB\n",
            "None\n",
            "\n",
            "--- COLUMNAS CATEGÓRICAS ---\n",
            "['iso3c', 'country']\n",
            "\n",
            "--- COLUMNAS NUMÉRICAS ---\n",
            "['year', 'gdp_pc', 'life_exp', 'urban_pct', 'co2_pc', 'unemp', 'infl', 'trade_gdp', 'internet']\n",
            "\n",
            "--- NULOS (conteo y %) ---\n",
            "           nulos  pct_nulos\n",
            "trade_gdp    513      14.38\n",
            "internet     487      13.65\n",
            "unemp        383      10.73\n",
            "infl         371      10.40\n",
            "co2_pc       177       4.96\n",
            "iso3c          0       0.00\n",
            "country        0       0.00\n",
            "year           0       0.00\n",
            "urban_pct      0       0.00\n",
            "gdp_pc         0       0.00\n",
            "life_exp       0       0.00\n",
            "\n",
            "--- DESCRIPTIVA NUMÉRICAS ---\n",
            "            count          mean           std          min          25%  \\\n",
            "year       3568.0   2016.467769      4.025441  2010.000000  2013.000000   \n",
            "gdp_pc     3568.0  17219.169029  25881.670535   216.727705  2194.069720   \n",
            "life_exp   3568.0     71.849650      7.876746    18.818000    66.448250   \n",
            "urban_pct  3568.0     59.608268     22.519827    10.984310    41.669843   \n",
            "co2_pc     3391.0      4.701622      8.199278     0.000000     0.720731   \n",
            "unemp      3185.0      7.627959      5.469889     0.100000     4.036000   \n",
            "infl       3197.0      5.711133     16.664453    -4.644709     1.560079   \n",
            "trade_gdp  3055.0     87.003537     55.632483     2.473729    52.778531   \n",
            "internet   3081.0     51.405981     29.461354     0.250000    24.304400   \n",
            "\n",
            "                   50%           75%            max  missing  missing_pct  \n",
            "year       2016.000000   2020.000000    2023.000000        0         0.00  \n",
            "gdp_pc     6545.446169  21382.817361  256799.788613        0         0.00  \n",
            "life_exp     72.788500     77.584201      86.372000        0         0.00  \n",
            "urban_pct    59.703873     77.895308     100.000000        0         0.00  \n",
            "co2_pc        2.637445      6.004584     202.865184      177         4.96  \n",
            "unemp         6.042158      9.427890      36.472000      383        10.73  \n",
            "infl          3.316056      5.978025     557.201817      371        10.40  \n",
            "trade_gdp    73.153262    104.874735     679.232773      513        14.38  \n",
            "internet     54.000000     77.669600     100.000000      487        13.65  \n",
            "\n",
            "[OK] Histogramas guardados en: outputs/figures\n",
            "\n",
            "--- OUTLIERS (regla IQR) ---\n",
            "    variable  n_outliers_IQR   lim_inf_IQR   lim_sup_IQR\n",
            "0     gdp_pc             327 -26589.051742  50165.938822\n",
            "4      unemp             238     -4.051836     17.515726\n",
            "3     co2_pc             213     -7.205049     13.930365\n",
            "5       infl             211     -5.066841     12.604945\n",
            "6  trade_gdp             119    -25.365774    183.019041\n",
            "1   life_exp              19     49.744323     94.288128\n",
            "2  urban_pct               0    -12.668354    132.233505\n",
            "7   internet               0    -55.743400    157.717400\n",
            "\n",
            "[OK] Boxplots guardados en: outputs/figures\n",
            "\n",
            "[OK] Guardado: outputs/data/wdi_dataset_con_log.csv (incluye log_gdp_pc)\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# SECCIÓN 2: EDA (tipos de variables, descriptiva, missing, outliers + gráficos)\n",
        "# ==========================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "FIG_DIR = os.path.join(\"outputs\", \"figures\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "# ---------------------------\n",
        "# 2.1) Cargar dataset ya construido (por seguridad/reproducibilidad)\n",
        "# ---------------------------\n",
        "df = pd.read_csv(\"outputs/data/wdi_dataset.csv\")\n",
        "\n",
        "print(\"\\n--- INFO GENERAL ---\")\n",
        "print(df.info())\n",
        "\n",
        "# ---------------------------\n",
        "# 2.2) Identificar tipos de variables\n",
        "# ---------------------------\n",
        "cat_cols = [\"iso3c\", \"country\"]\n",
        "num_cols = [c for c in df.columns if c not in cat_cols]\n",
        "\n",
        "print(\"\\n--- COLUMNAS CATEGÓRICAS ---\")\n",
        "print(cat_cols)\n",
        "\n",
        "print(\"\\n--- COLUMNAS NUMÉRICAS ---\")\n",
        "print(num_cols)\n",
        "\n",
        "# ---------------------------\n",
        "# 2.3) Missing values (conteo y porcentaje)\n",
        "# ---------------------------\n",
        "missing_count = df.isna().sum()\n",
        "missing_pct = (missing_count / len(df) * 100).round(2)\n",
        "missing_table = pd.DataFrame({\"nulos\": missing_count, \"pct_nulos\": missing_pct}).sort_values(\"nulos\", ascending=False)\n",
        "\n",
        "print(\"\\n--- NULOS (conteo y %) ---\")\n",
        "print(missing_table)\n",
        "\n",
        "# Guardar tabla de nulos (por si la quieres para el informe)\n",
        "missing_table.to_csv(\"outputs/data/missing_table.csv\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2.4) Estadística descriptiva (numéricas)\n",
        "# ---------------------------\n",
        "desc = df[num_cols].describe().T\n",
        "desc[\"missing\"] = df[num_cols].isna().sum()\n",
        "desc[\"missing_pct\"] = (desc[\"missing\"] / len(df) * 100).round(2)\n",
        "\n",
        "print(\"\\n--- DESCRIPTIVA NUMÉRICAS ---\")\n",
        "print(desc)\n",
        "\n",
        "desc.to_csv(\"outputs/data/descriptiva_numericas.csv\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2.5) Gráficos: histogramas (distribuciones)\n",
        "# ---------------------------\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "vars_to_plot = [\"gdp_pc\", \"life_exp\", \"urban_pct\", \"co2_pc\", \"unemp\", \"infl\", \"trade_gdp\", \"internet\"]\n",
        "\n",
        "for v in vars_to_plot:\n",
        "    if v not in df.columns:\n",
        "        continue\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    sns.histplot(df[v], kde=True)\n",
        "    plt.title(f\"Distribución de {v}\")\n",
        "    plt.xlabel(v)\n",
        "    plt.ylabel(\"Frecuencia\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(FIG_DIR, f\"hist_{v}.png\"), dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "print(f\"\\n[OK] Histogramas guardados en: {FIG_DIR}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2.6) Outliers: boxplots + detección por IQR (solo numéricas)\n",
        "# ---------------------------\n",
        "def iqr_outliers(s: pd.Series):\n",
        "    \"\"\"Devuelve máscara booleana de outliers según regla IQR (1.5*IQR).\"\"\"\n",
        "    x = s.dropna()\n",
        "    q1 = x.quantile(0.25)\n",
        "    q3 = x.quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    low = q1 - 1.5 * iqr\n",
        "    high = q3 + 1.5 * iqr\n",
        "    return (s < low) | (s > high), low, high\n",
        "\n",
        "outlier_summary = []\n",
        "\n",
        "for v in vars_to_plot:\n",
        "    if v not in df.columns:\n",
        "        continue\n",
        "\n",
        "    # Boxplot\n",
        "    plt.figure(figsize=(8, 3))\n",
        "    sns.boxplot(x=df[v])\n",
        "    plt.title(f\"Boxplot de {v} (outliers visuales)\")\n",
        "    plt.xlabel(v)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(FIG_DIR, f\"box_{v}.png\"), dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "    # Conteo outliers por IQR\n",
        "    mask, low, high = iqr_outliers(df[v])\n",
        "    n_out = int(mask.sum())\n",
        "    outlier_summary.append({\"variable\": v, \"n_outliers_IQR\": n_out, \"lim_inf_IQR\": low, \"lim_sup_IQR\": high})\n",
        "\n",
        "outlier_df = pd.DataFrame(outlier_summary).sort_values(\"n_outliers_IQR\", ascending=False)\n",
        "print(\"\\n--- OUTLIERS (regla IQR) ---\")\n",
        "print(outlier_df)\n",
        "\n",
        "outlier_df.to_csv(\"outputs/data/outliers_iqr.csv\", index=False)\n",
        "print(f\"\\n[OK] Boxplots guardados en: {FIG_DIR}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 2.7) Sugerencia práctica: gdp_pc suele ser muy sesgada → log para análisis/modelo\n",
        "# ---------------------------\n",
        "df[\"log_gdp_pc\"] = np.log(df[\"gdp_pc\"])\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(df[\"log_gdp_pc\"], kde=True)\n",
        "plt.title(\"Distribución de log_gdp_pc (log del PIB per cápita)\")\n",
        "plt.xlabel(\"log_gdp_pc\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, \"hist_log_gdp_pc.png\"), dpi=200)\n",
        "plt.close()\n",
        "\n",
        "df.to_csv(\"outputs/data/wdi_dataset_con_log.csv\", index=False)\n",
        "print(\"\\n[OK] Guardado: outputs/data/wdi_dataset_con_log.csv (incluye log_gdp_pc)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# SECCIÓN 3: Correlaciones + visualizaciones\n",
        "# ==========================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "FIG_DIR = os.path.join(\"outputs\", \"figures\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "# Cargar dataset con log (asegura que existe log_gdp_pc)\n",
        "df = pd.read_csv(\"outputs/data/wdi_dataset_con_log.csv\")\n",
        "\n",
        "# Columnas numéricas para correlación (excluimos iso3c/country)\n",
        "num_cols = [\"year\", \"gdp_pc\", \"log_gdp_pc\", \"life_exp\", \"urban_pct\", \"co2_pc\", \"unemp\", \"infl\", \"trade_gdp\", \"internet\"]\n",
        "\n",
        "# ---------------------------\n",
        "# 3.1) Matriz de correlación (Pearson) con eliminación por pares (pairwise)\n",
        "# ---------------------------\n",
        "corr = df[num_cols].corr(method=\"pearson\", min_periods=200)  # min_periods evita correlaciones con muy pocos datos\n",
        "\n",
        "print(\"\\n--- CORRELACIÓN (Pearson) ---\")\n",
        "print(corr)\n",
        "\n",
        "# Heatmap\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(corr, annot=False, cmap=\"coolwarm\", center=0, linewidths=0.5)\n",
        "plt.title(\"Matriz de correlación (Pearson) - WDI\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, \"corr_heatmap.png\"), dpi=200)\n",
        "plt.close()\n",
        "\n",
        "print(f\"\\n[OK] Heatmap guardado en: {os.path.join(FIG_DIR, 'corr_heatmap.png')}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 3.2) Correlaciones con la variable objetivo (log_gdp_pc)\n",
        "# ---------------------------\n",
        "target = \"log_gdp_pc\"\n",
        "corr_target = corr[target].drop(labels=[target, \"gdp_pc\"]).sort_values(key=lambda s: s.abs(), ascending=False)\n",
        "\n",
        "print(\"\\n--- CORRELACIONES con log_gdp_pc (ordenadas por magnitud) ---\")\n",
        "print(corr_target)\n",
        "\n",
        "corr_target.to_csv(\"outputs/data/correlaciones_con_target.csv\")\n",
        "\n",
        "# ---------------------------\n",
        "# 3.3) Scatterplots con línea de regresión para las 4 X más correlacionadas\n",
        "# ---------------------------\n",
        "top4 = corr_target.index[:4].tolist()\n",
        "print(\"\\nVariables top4 para scatter/regplot:\", top4)\n",
        "\n",
        "for x in top4:\n",
        "    tmp = df[[target, x]].dropna()\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.regplot(data=tmp, x=x, y=target, scatter_kws={\"s\": 12}, line_kws={\"linewidth\": 2})\n",
        "    plt.title(f\"{target} vs {x}\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(FIG_DIR, f\"scatter_{target}_vs_{x}.png\"), dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "print(f\"\\n[OK] Scatters guardados en: {FIG_DIR}\")\n",
        "\n",
        "# ---------------------------\n",
        "# 3.4) (Opcional, útil) correlación sin 'year' para no mezclar tendencia temporal\n",
        "# ---------------------------\n",
        "cols_no_year = [c for c in num_cols if c != \"year\"]\n",
        "corr_no_year = df[cols_no_year].corr(method=\"pearson\", min_periods=200)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(corr_no_year, annot=False, cmap=\"coolwarm\", center=0, linewidths=0.5)\n",
        "plt.title(\"Matriz de correlación (Pearson) - sin year\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, \"corr_heatmap_sin_year.png\"), dpi=200)\n",
        "plt.close()\n",
        "\n",
        "print(f\"[OK] Heatmap sin year guardado en: {os.path.join(FIG_DIR, 'corr_heatmap_sin_year.png')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SnfICG4gD52",
        "outputId": "32290342-a012-4659-cc13-0c02adf1d3c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- CORRELACIÓN (Pearson) ---\n",
            "                year    gdp_pc  log_gdp_pc  life_exp  urban_pct    co2_pc  \\\n",
            "year        1.000000  0.041602    0.051597  0.092076   0.056708 -0.025899   \n",
            "gdp_pc      0.041602  1.000000    0.778487  0.607038   0.458189  0.365904   \n",
            "log_gdp_pc  0.051597  0.778487    1.000000  0.837712   0.686195  0.432432   \n",
            "life_exp    0.092076  0.607038    0.837712  1.000000   0.607606  0.329202   \n",
            "urban_pct   0.056708  0.458189    0.686195  0.607606   1.000000  0.366550   \n",
            "co2_pc     -0.025899  0.365904    0.432432  0.329202   0.366550  1.000000   \n",
            "unemp      -0.068143 -0.110206    0.039293 -0.007783   0.121685 -0.111580   \n",
            "infl        0.089704 -0.109356   -0.138008 -0.101978  -0.040124 -0.057791   \n",
            "trade_gdp   0.000307  0.365196    0.371004  0.288261   0.289461  0.153287   \n",
            "internet    0.417445  0.592472    0.836081  0.801740   0.662747  0.540775   \n",
            "\n",
            "               unemp      infl  trade_gdp  internet  \n",
            "year       -0.068143  0.089704   0.000307  0.417445  \n",
            "gdp_pc     -0.110206 -0.109356   0.365196  0.592472  \n",
            "log_gdp_pc  0.039293 -0.138008   0.371004  0.836081  \n",
            "life_exp   -0.007783 -0.101978   0.288261  0.801740  \n",
            "urban_pct   0.121685 -0.040124   0.289461  0.662747  \n",
            "co2_pc     -0.111580 -0.057791   0.153287  0.540775  \n",
            "unemp       1.000000  0.018588   0.037272  0.056248  \n",
            "infl        0.018588  1.000000  -0.096002 -0.054782  \n",
            "trade_gdp   0.037272 -0.096002   1.000000  0.316205  \n",
            "internet    0.056248 -0.054782   0.316205  1.000000  \n",
            "\n",
            "[OK] Heatmap guardado en: outputs/figures/corr_heatmap.png\n",
            "\n",
            "--- CORRELACIONES con log_gdp_pc (ordenadas por magnitud) ---\n",
            "life_exp     0.837712\n",
            "internet     0.836081\n",
            "urban_pct    0.686195\n",
            "co2_pc       0.432432\n",
            "trade_gdp    0.371004\n",
            "infl        -0.138008\n",
            "year         0.051597\n",
            "unemp        0.039293\n",
            "Name: log_gdp_pc, dtype: float64\n",
            "\n",
            "Variables top4 para scatter/regplot: ['life_exp', 'internet', 'urban_pct', 'co2_pc']\n",
            "\n",
            "[OK] Scatters guardados en: outputs/figures\n",
            "[OK] Heatmap sin year guardado en: outputs/figures/corr_heatmap_sin_year.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# SECCIÓN 4: Regresión lineal (OLS) + métricas (R², MSE, MAE)\n",
        "# ==========================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "FIG_DIR = os.path.join(\"outputs\", \"figures\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "# 4.1) Cargar dataset con log\n",
        "df = pd.read_csv(\"outputs/data/wdi_dataset_con_log.csv\")\n",
        "\n",
        "# Variable objetivo (y) y explicativas (X)\n",
        "y_col = \"log_gdp_pc\"\n",
        "x_cols = [\"life_exp\", \"internet\", \"urban_pct\", \"co2_pc\", \"trade_gdp\", \"infl\", \"unemp\"]  # modelo base (sin year)\n",
        "\n",
        "# 4.2) Construir dataset del modelo (dropna solo en las columnas del modelo)\n",
        "df_model = df[[y_col] + x_cols].dropna().copy()\n",
        "\n",
        "print(\"\\n--- REGRESIÓN OLS: datos usados ---\")\n",
        "print(\"Observaciones totales:\", df.shape[0])\n",
        "print(\"Observaciones usadas en regresión (sin NaN):\", df_model.shape[0])\n",
        "print(\"Observaciones descartadas por NaN:\", df.shape[0] - df_model.shape[0])\n",
        "\n",
        "# 4.3) Train / Test split (para evaluar fuera de muestra)\n",
        "X = df_model[x_cols]\n",
        "y = df_model[y_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "# 4.4) Ajustar OLS con constante\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "X_test_sm = sm.add_constant(X_test)\n",
        "\n",
        "model = sm.OLS(y_train, X_train_sm).fit()\n",
        "\n",
        "print(\"\\n--- RESUMEN DEL MODELO (OLS) ---\")\n",
        "print(model.summary())\n",
        "\n",
        "# Guardar resumen a txt (útil para el informe)\n",
        "with open(\"outputs/data/ols_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(model.summary().as_text())\n",
        "\n",
        "# 4.5) Predicción y métricas\n",
        "y_pred = model.predict(X_test_sm)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(\"\\n--- MÉTRICAS (test) ---\")\n",
        "print(f\"R²:  {r2:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "metrics_df = pd.DataFrame([{\"R2_test\": r2, \"MSE_test\": mse, \"MAE_test\": mae, \"n_train\": len(X_train), \"n_test\": len(X_test)}])\n",
        "metrics_df.to_csv(\"outputs/data/ols_metrics.csv\", index=False)\n",
        "\n",
        "# 4.6) Gráficos diagnósticos básicos (residuos)\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# Residuo vs predicción\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.scatter(y_pred, residuals, s=12)\n",
        "plt.axhline(0)\n",
        "plt.title(\"Residuos vs Predicción (test)\")\n",
        "plt.xlabel(\"Predicción (log_gdp_pc)\")\n",
        "plt.ylabel(\"Residuo\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, \"residuos_vs_pred.png\"), dpi=200)\n",
        "plt.close()\n",
        "\n",
        "# Histograma de residuos\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.hist(residuals, bins=30)\n",
        "plt.title(\"Distribución de residuos (test)\")\n",
        "plt.xlabel(\"Residuo\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, \"hist_residuos.png\"), dpi=200)\n",
        "plt.close()\n",
        "\n",
        "print(\"\\n[OK] Guardado: outputs/data/ols_summary.txt y outputs/data/ols_metrics.csv\")\n",
        "print(\"[OK] Gráficos: residuos_vs_pred.png e hist_residuos.png en outputs/figures\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIGOpskehCvx",
        "outputId": "0f4aba6a-416d-40a9-c6bb-4566b8355611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- REGRESIÓN OLS: datos usados ---\n",
            "Observaciones totales: 3568\n",
            "Observaciones usadas en regresión (sin NaN): 2441\n",
            "Observaciones descartadas por NaN: 1127\n",
            "\n",
            "--- RESUMEN DEL MODELO (OLS) ---\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:             log_gdp_pc   R-squared:                       0.852\n",
            "Model:                            OLS   Adj. R-squared:                  0.851\n",
            "Method:                 Least Squares   F-statistic:                     1497.\n",
            "Date:                Fri, 13 Feb 2026   Prob (F-statistic):               0.00\n",
            "Time:                        19:37:43   Log-Likelihood:                -1458.4\n",
            "No. Observations:                1830   AIC:                             2933.\n",
            "Df Residuals:                    1822   BIC:                             2977.\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          2.1850      0.176     12.388      0.000       1.839       2.531\n",
            "life_exp       0.0661      0.003     22.757      0.000       0.060       0.072\n",
            "internet       0.0125      0.001     15.483      0.000       0.011       0.014\n",
            "urban_pct      0.0138      0.001     14.742      0.000       0.012       0.016\n",
            "co2_pc         0.0416      0.003     14.722      0.000       0.036       0.047\n",
            "trade_gdp      0.0016      0.000      6.497      0.000       0.001       0.002\n",
            "infl          -0.0034      0.001     -4.678      0.000      -0.005      -0.002\n",
            "unemp          0.0023      0.002      0.911      0.363      -0.003       0.007\n",
            "==============================================================================\n",
            "Omnibus:                       23.518   Durbin-Watson:                   1.940\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               34.643\n",
            "Skew:                           0.126   Prob(JB):                     3.00e-08\n",
            "Kurtosis:                       3.625   Cond. No.                     2.04e+03\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 2.04e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "\n",
            "--- MÉTRICAS (test) ---\n",
            "R²:  0.8494\n",
            "MSE: 0.2906\n",
            "MAE: 0.4244\n",
            "\n",
            "[OK] Guardado: outputs/data/ols_summary.txt y outputs/data/ols_metrics.csv\n",
            "[OK] Gráficos: residuos_vs_pred.png e hist_residuos.png en outputs/figures\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# SECCIÓN 5: Tablas y gráficos finales (para el informe) + VIF\n",
        "# ==========================================\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "FIG_DIR = os.path.join(\"outputs\", \"figures\")\n",
        "DATA_DIR = os.path.join(\"outputs\", \"data\")\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(\"outputs/data/wdi_dataset_con_log.csv\")\n",
        "\n",
        "y_col = \"log_gdp_pc\"\n",
        "x_cols = [\"life_exp\", \"internet\", \"urban_pct\", \"co2_pc\", \"trade_gdp\", \"infl\", \"unemp\"]\n",
        "\n",
        "df_model = df[[y_col] + x_cols].dropna().copy()\n",
        "\n",
        "X = df_model[x_cols]\n",
        "y = df_model[y_col]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "X_test_sm = sm.add_constant(X_test)\n",
        "\n",
        "model = sm.OLS(y_train, X_train_sm).fit()\n",
        "y_pred = model.predict(X_test_sm)\n",
        "\n",
        "# ---- 5.1) Tabla de coeficientes (para pegar en el informe)\n",
        "coef_table = pd.DataFrame({\n",
        "    \"coef\": model.params,\n",
        "    \"std_err\": model.bse,\n",
        "    \"t\": model.tvalues,\n",
        "    \"p_value\": model.pvalues\n",
        "})\n",
        "coef_table.to_csv(os.path.join(DATA_DIR, \"tabla_coeficientes.csv\"))\n",
        "\n",
        "# ---- 5.2) Métricas (test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "metrics_df = pd.DataFrame([{\n",
        "    \"R2_test\": r2, \"MSE_test\": mse, \"MAE_test\": mae,\n",
        "    \"n_total_model\": len(df_model), \"n_train\": len(X_train), \"n_test\": len(X_test)\n",
        "}])\n",
        "metrics_df.to_csv(os.path.join(DATA_DIR, \"metricas_finales.csv\"), index=False)\n",
        "\n",
        "# ---- 5.3) Predicho vs Real (scatter)\n",
        "plt.figure(figsize=(5.5, 4.5))\n",
        "plt.scatter(y_test, y_pred, s=12)\n",
        "plt.title(\"Predicho vs Real (log_gdp_pc) - Test\")\n",
        "plt.xlabel(\"Real (log_gdp_pc)\")\n",
        "plt.ylabel(\"Predicho (log_gdp_pc)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(FIG_DIR, \"predicho_vs_real.png\"), dpi=200)\n",
        "plt.close()\n",
        "\n",
        "# ---- 5.4) VIF (para revisar multicolinealidad)\n",
        "# VIF = 1/(1-R2_j) donde R2_j es al regredir X_j contra las demás X\n",
        "def compute_vif(X_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    Xv = X_df.dropna().copy()\n",
        "    out = []\n",
        "    for col in Xv.columns:\n",
        "        yj = Xv[col]\n",
        "        Xj = Xv.drop(columns=[col])\n",
        "        Xj = sm.add_constant(Xj)\n",
        "        r2j = sm.OLS(yj, Xj).fit().rsquared\n",
        "        vif = 1.0 / (1.0 - r2j) if r2j < 0.999999 else np.inf\n",
        "        out.append({\"variable\": col, \"VIF\": vif})\n",
        "    return pd.DataFrame(out).sort_values(\"VIF\", ascending=False)\n",
        "\n",
        "vif_df = compute_vif(X)\n",
        "vif_df.to_csv(os.path.join(DATA_DIR, \"vif.csv\"), index=False)\n",
        "\n",
        "print(\"\\n[OK] Guardado para informe:\")\n",
        "print(\"- outputs/data/tabla_coeficientes.csv\")\n",
        "print(\"- outputs/data/metricas_finales.csv\")\n",
        "print(\"- outputs/data/vif.csv\")\n",
        "print(\"- outputs/figures/predicho_vs_real.png\")\n",
        "print(\"\\nMétricas test:\", {\"R2\": r2, \"MSE\": mse, \"MAE\": mae})\n",
        "print(\"\\nVIF (top):\")\n",
        "print(vif_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg6xp8cVhtiA",
        "outputId": "0eedcb52-3f5b-42c6-9c43-a67f4d56b6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[OK] Guardado para informe:\n",
            "- outputs/data/tabla_coeficientes.csv\n",
            "- outputs/data/metricas_finales.csv\n",
            "- outputs/data/vif.csv\n",
            "- outputs/figures/predicho_vs_real.png\n",
            "\n",
            "Métricas test: {'R2': 0.8494009801711508, 'MSE': 0.29058636489396805, 'MAE': 0.42443435263921175}\n",
            "\n",
            "VIF (top):\n",
            "    variable       VIF\n",
            "1   internet  3.655510\n",
            "0   life_exp  3.261560\n",
            "2  urban_pct  2.583787\n",
            "3     co2_pc  1.678970\n",
            "4  trade_gdp  1.146824\n",
            "6      unemp  1.091880\n",
            "5       infl  1.018628\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20466916",
        "outputId": "46db8781-8b54-4dba-8779-50576f17b036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Define the directory containing the figures\n",
        "FIG_DIR = os.path.join(\"outputs\", \"figures\")\n",
        "\n",
        "# Define the name for the zip archive\n",
        "zip_filename = \"wdi_figures.zip\"\n",
        "zip_path = os.path.join(\"outputs\", zip_filename)\n",
        "\n",
        "# Create the zip archive\n",
        "# The root_dir is the directory to start zipping from (e.g., 'outputs')\n",
        "# The base_dir is the directory inside root_dir to zip (e.g., 'figures')\n",
        "shutil.make_archive(zip_path.replace('.zip', ''), 'zip', root_dir='outputs', base_dir='figures')\n",
        "\n",
        "print(f\"[OK] Archivo ZIP creado: {zip_path}\")\n",
        "\n",
        "# Provide a download link\n",
        "files.download(zip_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Archivo ZIP creado: outputs/wdi_figures.zip\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6c832ea8-5802-4825-8c4e-ee7df21a61e7\", \"wdi_figures.zip\", 1623903)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}